{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856dd5ef-9345-4948-89ae-caa572baa509",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff98d5-f74d-4e26-a542-4cf00a5607b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob \n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for data logging\n",
    "\n",
    "import clearml\n",
    "\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=UQB0N20QFCMKPOCW8QLK\n",
    "%env CLEARML_API_SECRET_KEY=SVw5WBc553aYTQWF1Hnac5j6TvSddL8X9K8kmQ6Pd6maMopExc\n",
    "\n",
    "clearml.browser_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure your work directory is sed to root folder of the project\n",
    "\n",
    "DATASET = 'FieldPlant'\n",
    "work_directory = Path().absolute()\n",
    "print(work_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba3384-dc07-4b5e-9ad4-4464ba825400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc functions to be used later\n",
    "\n",
    "# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n",
    "def yolo2bbox(bboxes):\n",
    "    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n",
    "    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def plot_box(image, bboxes, labels):\n",
    "    # Need the image height and width to denormalize\n",
    "    # the bounding box coordinates\n",
    "    h, w, _ = image.shape\n",
    "    for box_num, box in enumerate(bboxes):\n",
    "        x1, y1, x2, y2 = yolo2bbox(box)\n",
    "        # Denormalize the coordinates.\n",
    "        xmin = int(x1*w)\n",
    "        ymin = int(y1*h)\n",
    "        xmax = int(x2*w)\n",
    "        ymax = int(y2*h)\n",
    "\n",
    "        thickness = max(2, int(w/275))\n",
    "                \n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            (xmin, ymin), (xmax, ymax),\n",
    "            color=(0, 0, 255),\n",
    "            thickness=thickness\n",
    "        )\n",
    "    return image\n",
    "\n",
    "# Function to plot images with the bounding boxes.\n",
    "def plot(image_paths, label_paths, num_samples):\n",
    "    all_images = []\n",
    "    all_images.extend(glob.glob(image_paths+'/*.jpg'))\n",
    "    all_images.extend(glob.glob(image_paths+'/*.JPG'))\n",
    "    \n",
    "    all_images.sort()\n",
    "\n",
    "    num_images = len(all_images)\n",
    "    \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i in range(num_samples):\n",
    "        j = random.randint(0,num_images-1)\n",
    "        image_name = all_images[j]\n",
    "        image_name = '.'.join(image_name.split(os.path.sep)[-1].split('.')[:-1])\n",
    "        image = cv2.imread(all_images[j])\n",
    "        with open(os.path.join(label_paths, image_name+'.txt'), 'r') as f:\n",
    "            bboxes = []\n",
    "            labels = []\n",
    "            label_lines = f.readlines()\n",
    "            for label_line in label_lines:\n",
    "                label = label_line[0]\n",
    "                bbox_string = label_line[2:]\n",
    "                x_c, y_c, w, h = bbox_string.lstrip().split(' ')\n",
    "                x_c = float(x_c)\n",
    "                y_c = float(y_c)\n",
    "                w = float(w)\n",
    "                h = float(h)\n",
    "                bboxes.append([x_c, y_c, w, h])\n",
    "                labels.append(label)\n",
    "        result_image = plot_box(image, bboxes, labels)\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(result_image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "    plt.subplots_adjust(wspace=1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebdba77-eb51-4aed-baac-357bac24d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few images before it get used for training\n",
    "plot(\n",
    "    image_paths = 'datasets/' + DATASET + '/train/images', \n",
    "    label_paths = 'datasets/' + DATASET + '/train/labels',\n",
    "    num_samples=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits dataset into train, validate, and test based on a ratio\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATASETS_DIR = Path('datasets/' + DATASET + '/train')\n",
    "\n",
    "IMG_FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm'  # include image suffixes\n",
    "\n",
    "def img2label_paths(img_paths):\n",
    "    # Define label paths as a function of image paths\n",
    "    sa, sb = f'{os.sep}images{os.sep}', f'{os.sep}labels{os.sep}'  # /images/, /labels/ substrings\n",
    "    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]\n",
    "\n",
    "def autosplit(path=DATASETS_DIR / 'images', weights=(0.9, 0.1, 0.0), annotated_only=False):\n",
    "    \"\"\" Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files\n",
    "    Usage: from utils.dataloaders import *; autosplit()\n",
    "    Arguments\n",
    "        path:            Path to images directory\n",
    "        weights:         Train, val, test weights (list, tuple)\n",
    "        annotated_only:  Only use images with an annotated txt file\n",
    "    \"\"\"\n",
    "    path = Path(path)  # images dir\n",
    "    files = sorted(x for x in path.rglob('*.*') if x.suffix[1:].lower() in IMG_FORMATS)  # image files only\n",
    "    n = len(files)  # number of files\n",
    "    random.seed(0)  # for reproducibility\n",
    "    indices = random.choices([0, 1, 2], weights=weights, k=n)  # assign each image to a split\n",
    "\n",
    "    txt = ['autosplit_train.txt', 'autosplit_val.txt', ]  # 2 txt files\n",
    "    for x in txt:\n",
    "        if (path.parent / x).exists():\n",
    "            (path.parent / x).unlink()  # remove existing\n",
    "\n",
    "    print(f'Autosplitting images from {path}' + ', using *.txt labeled images only' * annotated_only)\n",
    "    for i, img in tqdm(zip(indices, files), total=n):\n",
    "        if not annotated_only or Path(img2label_paths([str(img)])[0]).exists():  # check label\n",
    "            with open(path.parent / txt[i], 'a') as f:\n",
    "                f.write(f'./{img.relative_to(path.parent).as_posix()}' + '\\n')  # add image to txt file\n",
    "    \n",
    "    print(\"Split done!\")\n",
    "\n",
    "\n",
    "autosplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "OUTPUT_MODEL_NAME = 'plant-detection_' + DATASET + datetime.now().strftime(\"_%Y-%m-%d-%H-%M-%S\") \n",
    "\n",
    "# Load the model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data = work_directory / 'datasets' / DATASET / 'data.yaml',\n",
    "    imgsz = 1280,\n",
    "    epochs = 250,\n",
    "    batch = 32, # Use -1 for autobatch if you are unsure of your vram size\n",
    "    cache = 'ram', # comment this out if you don't have at least 64gb of ram\n",
    "    name = OUTPUT_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5527558-bdd6-4770-9cfd-35e7a7301fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "model = YOLO('runs/detect/' + OUTPUT_MODEL_NAME + '/weights/best.pt')\n",
    "\n",
    "metrics = model.val() # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a441cb-c182-4a2e-9739-84eed06a4a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes inferences\n",
    "model = YOLO('runs/detect/' + OUTPUT_MODEL_NAME + '/weights/best.pt')\n",
    "\n",
    "results = model.predict(\n",
    "    source = work_directory / 'datasets' / DATASET / 'train' / 'autosplit_val.txt',\n",
    "    imgsz = 1280,\n",
    "    name = OUTPUT_MODEL_NAME + '_infer',\n",
    "    show_labels = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "model = YOLO('runs/detect/' + OUTPUT_MODEL_NAME + '/weights/best.pt')\n",
    "image_folder = work_directory / 'datasets' / DATASET / 'train' / 'images'\n",
    "image_paths = glob.glob(f'{image_folder}/*.jpg')  # Adjust the pattern if necessary\n",
    "random_image_paths = random.sample(image_paths, min(len(image_paths), 4))\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))  # Adjust the figsize if necessary\n",
    "\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "# Run inference and show results for each of the four random images\n",
    "for idx, image_path in enumerate(random_image_paths):\n",
    "    # Run inference on the image\n",
    "    results = model(image_path)\n",
    "\n",
    "    # Show the results\n",
    "    for r in results:\n",
    "        im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "        im = Image.fromarray(im_array[..., ::-1])  # convert to RGB PIL image\n",
    "        axes_flat[idx].imshow(im)\n",
    "        axes_flat[idx].axis('off')  # Hide the axis\n",
    "\n",
    "# Adjust the layout and display the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('runs/detect/' + OUTPUT_MODEL_NAME + '/weights/best.pt')\n",
    "\n",
    "model.predict('test_video_3.mp4', save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
